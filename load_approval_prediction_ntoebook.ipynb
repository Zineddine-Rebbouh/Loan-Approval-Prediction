{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction\n",
    "\n",
    "## Project Overview\n",
    "This project builds a binary classification model to predict loan approval outcomes using the Kaggle Loan Approval Prediction Dataset. It includes data preprocessing, handling class imbalance with SMOTE, training Logistic Regression and Decision Tree models, and evaluating performance with precision, recall, and F1-score. A visualization of the target variable distribution is also included.\n",
    "\n",
    "## Requirements\n",
    "- Python 3.12+\n",
    "- Libraries: `numpy`, `pandas`, `matplotlib`, `scikit-learn`, `imblearn`\n",
    "- Dataset: [Loan Approval Prediction Dataset](https://www.kaggle.com/datasets/architsharma01/loan-approval-prediction-dataset)\n",
    "\n",
    "Install dependencies:\n",
    "```bash\n",
    "pip install numpy pandas matplotlib scikit-learn imblearn\n",
    "```\n",
    "\n",
    "## Dataset\n",
    "The dataset contains features like `loan_id`, `no_of_dependents`, `education`, `self_employed`, `income_annum`, `loan_amount`, `loan_term`, `cibil_score`, and the target `loan_status` (encoded as 0 for 'Rejected' and 1 for 'Approved')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Data\n",
    "Load the dataset and check its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv('data/raw_data/loan_approval_dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"Dataset not found. Ensure 'loan_approval_dataset.csv' is in 'data/raw_data/'.\")\n",
    "\n",
    "# Clean column names (remove leading/trailing spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Target Variable Distribution\n",
    "Plot the distribution of the target variable `loan_status` to understand class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target column\n",
    "target_column = 'loan_status'\n",
    "\n",
    "# Verify target column exists\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"Column '{target_column}' not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Calculate distribution\n",
    "status_counts = df[target_column].value_counts()\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(status_counts.index, status_counts.values, color=['#FF6B6B', '#4CAF50'], \n",
    "               edgecolor=['#D32F2F', '#388E3C'], linewidth=1)\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Loan Status')\n",
    "plt.xticks(status_counts.index, ['Rejected (0)', 'Approved (1)'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02*yval, int(yval), \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print unique values\n",
    "print(f\"Unique values in '{target_column}': {df[target_column].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "Handle missing values, encode categorical variables, and scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# Impute categorical columns with most frequent\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handle Class Imbalance with SMOTE\n",
    "Apply SMOTE to balance the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Print class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Models\n",
    "Train Logistic Regression and Decision Tree models, then evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_balanced, y_train_balanced)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Train Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_balanced, y_train_balanced)\n",
    "dt_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, lr_pred, target_names=['Rejected', 'Approved']))\n",
    "\n",
    "print(\"\\nDecision Tree Performance:\")\n",
    "print(classification_report(y_test, dt_pred, target_names=['Rejected', 'Approved']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Interpretation\n",
    "The Decision Tree model outperforms Logistic Regression, achieving higher precision, recall, and F1-score (approximately 0.97 vs. 0.91 overall accuracy). This suggests Decision Tree is better suited for this dataset, likely due to its ability to capture non-linear relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
